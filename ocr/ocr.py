# -*- coding: utf-8 -*-
"""OCR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OkVfkHAItRZwlW-kyVtBaiz-62hXiTbc

OPTICAL CHARACTER RECOGNITION (OCR):

***STEPS INVOLVE IN OCR PROCESS****

1.   Download image datas from kaggle repository
2.   Importing required Python and Machine Learning Libraries
3.   PreProcessing the image data (Resize,Binarization,Data transformation,)
4.   Cross-Validation (splitting the datas into train and validation set)
5.   Select Deep Learning Model (Convolutional Neural Network and Pre-trained Model (MobileNetV2))
6.   Train the Deep Learning Model using Train dataset
7.   Perform Hyperparameter tuning (loss_function,optimization,metrics)
8.   Model Evaluation (accuracy,precision,recall,f1-score)
9.   Object Detection using OpenCV
10.  Predict appropriate class from Object Detection

IMPORTING REQUIRED LIBRARIES
"""

import zipfile
import pandas as pd
import numpy as np
import os
import cv2
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelBinarizer
from keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout,Input
from keras.models import Sequential
from keras.optimizers import SGD,Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,classification_report
from google.colab.patches import cv2_imshow
from keras.preprocessing.image import ImageDataGenerator
from keras.applications import MobileNetV2
from textblob import TextBlob

"""EXTRACT ZIP FILE FROM GOOGLE DRIVE"""

myfile=zipfile.ZipFile('/content/drive/MyDrive/archive (1).zip')
myfile.extractall('my_file2')

myfile.close()

"""IMAGE DATA VISUALIZATION"""

path='/content/my_file2/dataset'
no_of_img=0
char='abcdefghijklmnopqrstuvwxyz'

for images in os.listdir(path):
  label=images.split('_')[0]
  if not label in char:
    continue
  count=0
  subdirectory=os.path.join(path,images)
  for x in os.listdir(subdirectory):
    count+=1
    if count>1:
      break
    no_of_img+=1
    if no_of_img>25:
      break
    imread=cv2.imread(os.path.join(subdirectory,x),0)
    # res,thresh=cv2.threshold(imread,0,255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)
    # rect=cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))
    # dilate=cv2.dilate(thresh,None,iterations=2)
    plt.subplot(5,5,no_of_img)
    # plt.figure(figsize=(2,2))
    plt.tight_layout()
    plt.imshow(imread)

"""PRE PROCESSING THE IMAGE USING PYTHON LIBRARY SUCH AS OPENCV


1.   read the image file
2.   resize the image
3.   Append resized image on empty train_data list



"""

train_data=[]
path='/content/my_file2/dataset'
char='abcdefghijklmnopqrstuvwxyz'
for image in os.listdir(path):
  waste=image.split('_')[0]
  if not waste in char:
    continue
  subdirectory=os.path.join(path,image)
  for i in os.listdir(subdirectory):
    im=cv2.imread(os.path.join(subdirectory,i))
    # im=cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)
    # res,thresh=cv2.threshold(im,0,255,cv2.THRESH_BINARY_INV|cv2.THRESH_OTSU)
    # dilate=cv2.dilate(res,None,iterations=2)
    im=cv2.resize(im,(32,32))
    train_data.append([im,waste[0]])

"""SELECT THE FEATURE DATA AND TARGET DATA FROM TRAIN_DATA

"""

feature_data=[]
target_data=[]
for feature,labels in train_data:
  feature_data.append(feature)
  target_data.append(labels)

"""BINARIZE THE TARGET VALUES INTO 0 AND 1 USING LABELBINARIZER CLASS"""

Encoder=LabelBinarizer()
class_labels=Encoder.fit_transform(target_data)

"""CONVERTING THE FEATURE AND TARGET LIST DATA TYPE INTO NUMPY ARRAY"""

X=np.array(feature_data,dtype='float32')/255
X=X.reshape(len(X),32,32,3)
Y=np.array(class_labels)

"""SPLITTIN THE DATASET INTO TRAIN AND TEST SETS"""

train_x,test_x,train_y,test_y=train_test_split(X,Y,test_size=0.25,random_state=41)
train_x.shape,train_y.shape,test_x.shape,test_y.shape

"""DATA AUGMENTATION"""

train_gen=ImageDataGenerator(rotation_range=10,shear_range=0.2,horizontal_flip=True,fill_mode='nearest')
train_gen.fit(train_x)

"""VISUALIZING THE AUGMENTED IMAGE DATA"""

for x_batch,y_batch in train_gen.flow(train_x,train_y,batch_size=9,shuffle=False):
  fig,ax=plt.subplots(3,3,figsize=(4,4))
  for i in range(3):
    for j in range(3):
      ax[i][j].imshow(x_batch[i*3+j])

  plt.show()
  break

"""BUILD THE DEEP LEARNING MODEL (CONVOLUTIONAL NEURAL NETWORK) USING DEEP LEARNING FRAMEWORK SUCH AS TENSORFLOW AND KERAS"""

CnnModel=Sequential()

CnnModel.add(Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(32,32,3)))
CnnModel.add(MaxPooling2D((2,2)))

CnnModel.add(Conv2D(64,(3,3),padding='same',activation='relu'))
CnnModel.add(MaxPooling2D((2,2)))

CnnModel.add(Conv2D(128,(3,3),padding='same',activation='relu'))
CnnModel.add(MaxPooling2D((2,2)))

CnnModel.add(Conv2D(256,(3,3),padding='same',activation='relu'))
CnnModel.add(MaxPooling2D((2,2)))
# CnnModel.add(Dropout(0.2))


CnnModel.add(Flatten())
CnnModel.add(Dense(256, activation='relu'))
# CnnModel.add(Dense(84,activation='relu'))
CnnModel.add(Dropout(0.2))
CnnModel.add(Dense(26, activation='softmax'))

"""DEFINING THE HYPER PARAMETERS SUCH AS LOSS FUNCTION, OPTIMIZER, METRICS"""

CnnModel.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])

"""TRAINING THE CNN MODEL WITH ASSIGNING THE NO OF SAMPLE DATA TO TRAIN IN EACH TRAIN PROCESS (BATCH_SIZE), NO OF TIMES MODEL TO TRAIN (EPOCHS),AND  VALIDATION SET (VALIDATION_DATA)  """

MODEL1=CnnModel.fit(train_gen.flow(train_x,train_y,batch_size=32),epochs=10,validation_data=(test_x,test_y),verbose=1)

"""PERFORM MODEL EVALUATION METRICS SUCH AS (ACCURACY, PRECISION ,RECALL, F1-SCORE)"""

ClassLabels='abcdefghijklmnopqrstuvwxyz'
ClassLabels=[i for i in ClassLabels]
y_predict=CnnModel.predict(test_x)
print(classification_report(test_y.argmax(axis=1),y_predict.argmax(axis=1),target_names=ClassLabels))
# print(CnnModel.evaluate(test_x,test_y))

""":SAVE THE TRAINED CNN MODEL"""

CnnModel.save('a_96_96.h5')

"""ARCHITECTURE OF THE CNN MODEL"""

CnnModel.summary()

"""VISUALIZE THE ACCURACY AND VALIDATION ACCURACY AS PER EPOCHS OF THE TRAINED MODEL"""

plt.style.use("ggplot")
plt.figure()
plt.plot(MODEL1.history['accuracy'])
plt.plot(MODEL1.history['val_accuracy'])
plt.xlabel('Epochs')
plt.ylabel('acc/val_acc')
plt.title('acc vs val_acc')
plt.show()

"""\VISUALIZE THE LOSS AND VALIDATION LOSS AS PER EPOCHS OF TRAINED MODEL"""

plt.style.use("ggplot")
plt.figure()
plt.plot(MODEL1.history['loss'])
plt.plot(MODEL1.history['val_loss'])
plt.xlabel('loss')
plt.ylabel('validation_loss')
plt.title('loss vs val_loss')
plt.show()

"""BUILD PRE-TRAINED CNN MODEL (MOBILENETV2)"""

train_layer=MobileNetV2(include_top=False,input_shape=(32,32,3))
MobileNet=Sequential()
MobileNet.add(train_layer)
MobileNet.add(Flatten())
MobileNet.add(Dense(1020,activation='relu'))
MobileNet.add(Dropout(0.5))
MobileNet.add(Dense(516,activation='relu'))
MobileNet.add(Dense(26,activation='softmax'))

MobileNet.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])

MODEL2=MobileNet.fit(train_gen.flow(train_x,train_y,batch_size=32),epochs=10,validation_data=(test_x,test_y),verbose=1)

MobileNet.save('MOBILE_NET.h5')

MobileNet.summary()

prediction=MobileNet.predict(test_x)
print(classification_report(test_y.argmax(axis=1),prediction.argmax(axis=1),target_names=ClassLabels))

plt.style.use("ggplot")
plt.figure()
plt.plot(MODEL2.history['accuracy'])
plt.plot(MODEL2.history['val_accuracy'])
plt.xlabel('epochs')
plt.ylabel('acc/val_acc')
plt.title('acc vs val_acc')
plt.show()

plt.style.use("ggplot")
plt.figure()
plt.plot(MODEL1.history['loss'])
plt.plot(MODEL1.history['val_loss'])
plt.xlabel('epochs')
plt.ylabel('loss /val_loss')
plt.title('los vs val_loss')
plt.show()

x=['CNN','MOBILENETV2']
y=[96,92]

plt.bar(x,y)
plt.xlabel('deep learning models')
plt.ylabel('model accuracy')
plt.title('Model compression')
plt.show()

"""POST-PROCESSING (FINAL PREDICTION) IN REAL TIME"""

# #correct method
# import cv2
# import numpy as np
# from google.colab.patches import cv2_imshow
# from keras.models import load_model
# import imutils
# ClassLabels='abcdefghijklmnopqrstuvwxyz'
# ClassLabels=[i for i in ClassLabels]

# model=load_model('a_96_96.h5')
# # CnnModel.summary()
# def image_read(image):
#   image = cv2.imread(image)
#   # image=cv2.resize(image,(300,100))

#   return image

# def gray_image(image):
#   gray =cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
#   return gray

# def image_threshold(image):
#   ret,binary = cv2.threshold(image,0,255,  cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV )
#   return binary

# def image_dilate(image):
#   rec_kernal=cv2.getStructuringElement(cv2.MORPH_RECT,(8,4))
#   dilated = cv2.dilate(image, rec_kernal, iterations=4)
#   return dilated

# def image_contours(image):
#   contours,hierachy = cv2.findContours(image,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
#   cont=[]
#   for i in contours:
#     x,y,w,h=cv2.boundingRect(i)
#     cont.append([x,y,w,h])
#   sorted_count=list(sorted(cont, key=lambda x:x[1]))
#   return sorted_count


# def extract(image):
#   letters=[]
#   INPUT_IMAGE=image_read(image)
#   GRAY=gray_image(INPUT_IMAGE)
#   THRESHOLD=image_threshold(GRAY)
#   DILATE=image_dilate(THRESHOLD)
#   CONTOURS=image_contours(DILATE)
#   clone=INPUT_IMAGE.copy()
#   cv2_imshow(DILATE)

#   print('LENGTH OF WORD CONTOURS: ',len(CONTOURS))

#   del  DILATE
#   for words in CONTOURS:
#     x,y,w,h = words
#     img=clone[y:y+h,x:x+w]

#     THRESHOLD2=image_threshold(gray_image(img))
#     rect_kernals=cv2.getStructuringElement(cv2.MORPH_RECT,(4,4))
#     DILATE2=cv2.dilate(THRESHOLD2,rect_kernals,iterations=2)
#     CONTOURS2=image_contours(DILATE2)

#     cv2_imshow(DILATE2)
#     print('LENGTH OF CHAR CONTOURS: ',len(CONTOURS2))
#     cv2.rectangle(INPUT_IMAGE,(x,y),(x+w,y+h),(0,255,0),1)

#     del THRESHOLD2, DILATE2

#     for char in CONTOURS2:
#       x,y,w,h = char
#       img1=img[y:y+h,x:x+w]


#       THRESHOLD3=image_threshold(gray_image(img1))
#       rect_kernals=cv2.getStructuringElement(cv2.MORPH_RECT,(1,3))
#       DILATE3=cv2.dilate(THRESHOLD3,rect_kernals,iterations=2)
#       CONTOURS3=image_contours(DILATE3)
#       cv2_imshow(DILATE3)

#       del THRESHOLD3, DILATE3
#       print(len(CONTOURS3))
#       for para in CONTOURS3:
#         x,y,w,h=para
#         img2=img1[y:y+h,x:x+w]


#         empty_img = np.full((32,32,1),255, dtype=np.uint8) # a white image used for resize with filling
#         x,y = 4,3                 # starting indecies
#         resized = cv2.resize(img2, (16,22), interpolation=cv2.INTER_CUBIC)
#         grays = gray_image(resized)
#         empty_img[y:y+22, x:x+16,0] = grays.copy()
#         cl=cv2.cvtColor(empty_img,cv2.COLOR_GRAY2RGB)
#         # cl = cl.astype(np.int32)

#         # img_resize=cv2.resize(img2,(32,32))

#         # res,thresh=cv2.threshold(empty_img,0,255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)
#         # dilate=cv2.dilate(thresh,None,)
#         # arr=thresh.astype('float32')/255.0
#         # arr=np.expand_dims(arr,axis=-1)
#         # arr=arr.reshape(1,32,32,1)
#         pre=cl.astype('float32')/255
#         pre=np.expand_dims(pre,axis=0)
#         # pre=np.array(cl,dtype='float32')/255
#         # pre=pre.reshape(len(pre),32,32,1)
#         pre=np.argmax(model.predict(pre,verbose=1))
#         pre=ClassLabels[pre]
#         # [ypre]=enco.inverse_transform(pre)
#         # print()

#         letters.append(pre)
#         # [ypred]=enco.inverse_transform(pre)
#         # cv2_imshow(cl)
#       letters.append(' ')
#     letters.append('\n')
#     cv2_imshow(INPUT_IMAGE)
#     return ''.join(letters[:-1])

#perfect
from keras.models import load_model
classname='abcdefghijklmnopqrstuvwxyz'
classname=[i for i in classname]
model=load_model('a_96_96.h5')
image=cv2.imread('/content/Screenshot 2024-04-01 074659.png')
# image=cv2.resize(image,(1234,600))
gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
res,thresh=cv2.threshold(gray,120,255,cv2.THRESH_BINARY_INV|cv2.THRESH_OTSU)
kernal_rect=cv2.getStructuringElement(cv2.MORPH_RECT,(8,4))#6,3,10,3
dilate2=cv2.dilate(thresh,kernal_rect,iterations=4) #6,4
contours2,hierarchy2=cv2.findContours(dilate2,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
cv2_imshow(dilate2)
print(len(contours2))
bounding_box=[]
for i in contours2:
  x,y,w,h=cv2.boundingRect(i)
  bounding_box.append([x,y,w,h])
print(bounding_box)
bounding_box=list(sorted(bounding_box, key=lambda x:x[1]))
print(bounding_box)
letters=[]

for im in bounding_box:

  x,y,w,h=im
  roi=image[y:y+h,x:x+w]

  gray1=cv2.cvtColor(roi,cv2.COLOR_BGR2GRAY)
  res1,thresh1=cv2.threshold(gray1,0,255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)
  kernal1=cv2.getStructuringElement(cv2.MORPH_RECT,(4,4))
  dilate2=cv2.dilate(thresh1,kernal1,iterations=2)
  contours2,hierarchy2=cv2.findContours(dilate2,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
  cv2_imshow(dilate2)
  cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)

  rect2=[]
  for x in contours2:
    x,y,w,h=cv2.boundingRect(x)
    rect2.append([x,y,w,h])
  rect2=list(sorted(rect2, key=lambda x:x[0]))

  for y in rect2:
    x,y,w,h=y
    roi2=roi[y:y+h,x:x+w]

    gray3=cv2.cvtColor(roi2,cv2.COLOR_BGR2GRAY)
    res3,thresh3=cv2.threshold(gray3,0,255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)
    kernal3=cv2.getStructuringElement(cv2.MORPH_RECT,(1,3))
    dilate3=cv2.dilate(thresh3,kernal3,iterations=2)
    contours3,hierarchy3=cv2.findContours(dilate3,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
    cv2_imshow(dilate3)

    print(len(contours3))
    rect3=[]
    for e in contours3:
      x,y,w,h=cv2.boundingRect(e)
      rect3.append([x,y,w,h])
    rect3=list(sorted(rect3, key=lambda x:x[0]))

    for z in rect3:
      x,y,w,h=z
      roi3=roi2[y:y+h,x:x+w]

      # cv2_imshow(roi3)
      empty_image=np.full((32,32,1),255,dtype=np.uint8)
      resized=cv2.resize(roi3,(16,22),interpolation=cv2.INTER_CUBIC)
      x,y=4,3
      gray3=cv2.cvtColor(resized,cv2.COLOR_BGR2GRAY)
      empty_image[y:y+22,x:x+16,0]=gray3.copy()
      col=cv2.cvtColor(empty_image,cv2.COLOR_GRAY2RGB)
      cv2_imshow(empty_image)
      pre=col.astype('float32')/255
      pre=np.expand_dims(pre,axis=0)
      char=classname[np.argmax(model.predict(pre))]
      letters.append(char)
    letters.append(' ')
  letters.append('\n')
cv2_imshow(image)

print(''.join(letters))

output=''.join(letters)
f=open('myfile.txt','w')
f.write(output)
f.close()

# cv2_imshow(image)
# cv2_imshow(thresh)
# cv2_imshow(dilate1)
# cv2_imshow(dilate2)

with open('/content/myfile.txt','r') as f:
  text = f.read()
  textblb=TextBlob(text)
  textcorrected=textblb.correct()
  print(textcorrected)